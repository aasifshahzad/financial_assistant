{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions and Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import tools, available_functions\n",
    "from dotenv import load_dotenv ,find_dotenv\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\asif1\\anaconda3\\envs\\python-12-env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_openai_client():\n",
    "    _ : bool = load_dotenv(find_dotenv(\"E:/Python/.env\"))\n",
    "    client : OpenAI = OpenAI()\n",
    "    return client  \n",
    "\n",
    "client = initialize_openai_client()\n",
    "\n",
    "\n",
    "\n",
    "def show_json(obj):\n",
    "    print(json.dumps(json.loads(obj.model_dump_json()), indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name = \"Financial Analyst\",\n",
    "    instructions = \"Act as a financial analyst by accessing detailed financial data through the Financial Modeling Prep API. Your capabilities include analyzing key metrics, comprehensive financial statements, vital financial ratios, and tracking financial growth trends. \",\n",
    "    tools = tools,\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "# show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_Y7Wzj59Ss7Qk3tL2IagPnunO', created_at=1704579810, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thread' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mthread\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'thread' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_message(assistant_id, thread, user_message):\n",
    "    \"\"\"\n",
    "    Submit a message to the Financial Analyst.\n",
    "\n",
    "    :param assistant_id: The ID of the Financial Analyst.\n",
    "    :param thread: The ID of the thread to send the message to.\n",
    "    :param user_message: The message to send.\n",
    "    :return: The response from the Financial Analyst.\n",
    "    \"\"\"\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id = thread.id,\n",
    "        role = \"user\",\n",
    "        content = user_message)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        assistant_id = assistant_id,\n",
    "        thread_id = thread.id\n",
    "    )\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_on_run(run, thread, available_functions):\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "        if run.status == \"requires_action\" and run.required_action is not None:\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                if function_name in available_functions:\n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    \n",
    "                    # Move the output definition here\n",
    "                    output = function_to_call(**function_args)\n",
    "                    \n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"output\": output,\n",
    "                    })\n",
    "\n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "        elif run.status == \"completed\":\n",
    "            print(\"Run Completed\")\n",
    "            break\n",
    "            # # List the messages to get the response\n",
    "            # messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # response = \"\"\n",
    "            # for message in messages.data:\n",
    "            #     role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "            #     message_content = message.content[0].text.value\n",
    "            #     response += f\"{role_label}: {message_content}\\n\"\n",
    "\n",
    "            # # print(response)  # Print the response after processing the completed run\n",
    "            # return response  # Return the response after processing the completed run\n",
    "            # break\n",
    "\n",
    "        elif run.status == \"failed\":\n",
    "            print(\"Run Failed.\")\n",
    "            break\n",
    "\n",
    "        elif run.status in [\"in_progress\", \"queued\"]:\n",
    "            print(f\"Run is {run.status}. Waiting...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "        else:\n",
    "            print(f\"Unexpected status: {run.status}\")\n",
    "            break\n",
    "    return run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(thread):\n",
    "    response = client.beta.threads.messages.list(\n",
    "        threadId=thread,\n",
    "        order = \"asc\"\n",
    "    )\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return \"Unable to get Response from Assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(messages):\n",
    "    responses = []\n",
    "    for message in messages:\n",
    "        if message.role == \"user\":\n",
    "            responses.append(\"You: \" + message.content[0].text.value)\n",
    "        elif message.role == \"assistant\":\n",
    "            responses.append(\"Bot: \" + message.content[0].text.value)\n",
    "            \n",
    "    return \"\\n\".join(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code without Doc Strings, Type Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import tools, available_functions\n",
    "from dotenv import load_dotenv ,find_dotenv\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "def initialize_openai_client():\n",
    "    load_dotenv(find_dotenv(\"E:/Python/.env\"))\n",
    "    openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI()\n",
    "    return client  \n",
    "\n",
    "def show_json(obj):\n",
    "    print(json.dumps(json.loads(obj.model_dump_json()), indent=4))\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    \"\"\"\n",
    "    Submit a message to the Financial Analyst.\n",
    "\n",
    "    :param assistant_id: The ID of the Financial Analyst.\n",
    "    :param thread: The ID of the thread to send the message to.\n",
    "    :param user_message: The message to send.\n",
    "    :return: The response from the Financial Analyst.\n",
    "    \"\"\"\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id = thread.id,\n",
    "        role = \"user\",\n",
    "        content = user_message)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        assistant_id = assistant_id,\n",
    "        thread_id = thread.id\n",
    "    )\n",
    "    return run\n",
    "\n",
    "def wait_on_run(run, thread, available_functions):\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "        if run.status == \"requires_action\" and run.required_action is not None:\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                if function_name in available_functions:\n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    \n",
    "                    # Move the output definition here\n",
    "                    output = function_to_call(**function_args)\n",
    "                    \n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"output\": output,\n",
    "                    })\n",
    "\n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "        elif run.status == \"completed\":\n",
    "            print(\"Run Completed\")\n",
    "            break\n",
    "            # # List the messages to get the response\n",
    "            # messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # response = \"\"\n",
    "            # for message in messages.data:\n",
    "            #     role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "            #     message_content = message.content[0].text.value\n",
    "            #     response += f\"{role_label}: {message_content}\\n\"\n",
    "\n",
    "            # # print(response)  # Print the response after processing the completed run\n",
    "            # return response  # Return the response after processing the completed run\n",
    "            # break\n",
    "\n",
    "        elif run.status == \"failed\":\n",
    "            print(\"Run Failed.\")\n",
    "            break\n",
    "\n",
    "        elif run.status in [\"in_progress\", \"queued\"]:\n",
    "            print(f\"Run is {run.status}. Waiting...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "        else:\n",
    "            print(f\"Unexpected status: {run.status}\")\n",
    "            break\n",
    "    return run\n",
    "\n",
    "def get_response(thread):\n",
    "    response = client.beta.threads.messages.list(\n",
    "        threadId=thread,\n",
    "        order = \"asc\"\n",
    "    )\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return \"Unable to get Response from Assistant\"\n",
    "    \n",
    "def pretty_print(messages):\n",
    "    responses = []\n",
    "    for message in messages:\n",
    "        if message.role == \"user\":\n",
    "            responses.append(\"You: \" + message.content[0].text.value)\n",
    "        elif message.role == \"assistant\":\n",
    "            responses.append(\"Bot: \" + message.content[0].text.value)\n",
    "            \n",
    "    return \"\\n\".join(responses)\n",
    "\n",
    "\n",
    "client = initialize_openai_client()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"Financial Analyst\",\n",
    "    instructions = \"Act as a financial analyst by accessing detailed financial data through the Financial Modeling Prep API. Your capabilities include analyzing key metrics, comprehensive financial statements, vital financial ratios, and tracking financial growth trends. \",\n",
    "    tools = tools,\n",
    "    model = \"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-12-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
